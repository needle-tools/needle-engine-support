import{_ as a,c as l,a as e,e as o,d as n,b as d,w as i,r as s,o as u}from"./app-9T6lAodh.js";const h={};function c(g,t){const r=s("RouteLink");return u(),l("div",null,[t[16]||(t[16]=e("h1",{id:"needle-kernkomponenten",tabindex:"-1"},[e("a",{class:"header-anchor",href:"#needle-kernkomponenten"},[e("span",null,"Needle-Kernkomponenten")])],-1)),t[17]||(t[17]=e("p",null,"Hier ist eine Übersicht über einige der von uns bereitgestellten Komponenten. Viele davon bilden Komponenten und Funktionen in Unity, Blender oder anderen Integrationen ab.",-1)),t[18]||(t[18]=e("p",null,[n("Eine vollständige Liste finden Sie in unserer "),e("a",{href:"https://engine.needle.tools/docs/api/latest",target:"_blank",rel:"noopener noreferrer"},"API-Dokumentation"),n(".")],-1)),t[19]||(t[19]=e("p",null,"Sie können jederzeit eigene Komponenten hinzufügen oder Wrapper für Unity-Komponenten erstellen, die wir noch nicht bereitgestellt haben.",-1)),e("p",null,[t[1]||(t[1]=n("Mehr dazu erfahren Sie im Abschnitt ")),d(r,{to:"/lang/de/scripting.html"},{default:i(()=>t[0]||(t[0]=[n("Skripting")])),_:1}),t[2]||(t[2]=n(" unserer Dokumentation."))]),t[20]||(t[20]=o('<h2 id="audio" tabindex="-1"><a class="header-anchor" href="#audio"><span>Audio</span></a></h2><table><thead><tr><th>Name</th><th>Beschreibung</th></tr></thead><tbody><tr><td><code>AudioListener</code></td><td></td></tr><tr><td><code>AudioSource</code></td><td>Zum Abspielen von Audio</td></tr></tbody></table><h2 id="animation" tabindex="-1"><a class="header-anchor" href="#animation"><span>Animation</span></a></h2><table><thead><tr><th>Name</th><th>Beschreibung</th></tr></thead><tbody><tr><td><code>Animator</code> mit <code>AnimatorController</code></td><td>Export mit Animations-Zustandsmaschine, Bedingungen, Übergängen</td></tr><tr><td><code>Animation</code></td><td>Grundlegendste Animationskomponente. Nur der erste Clip wird exportiert</td></tr><tr><td><code>PlayableDirector</code> mit <code>TimelineAsset</code></td><td>Exportieren Sie leistungsstarke Sequenzen zur Steuerung von Animation, Audio, Zustand und mehr</td></tr></tbody></table><h2 id="rendering" tabindex="-1"><a class="header-anchor" href="#rendering"><span>Rendering</span></a></h2><table><thead><tr><th>Name</th><th>Beschreibung</th></tr></thead><tbody><tr><td><code>Camera</code></td><td></td></tr><tr><td><code>Light</code></td><td>DirectionalLight, PointLight, Spotlight. Beachten Sie, dass Sie damit auch Licht backen können (z. B. rechteckige Lichtformen)</td></tr><tr><td><code>XRFlag</code></td><td>Steuert, wann Objekte sichtbar sind. Z.B. Objekt nur in AR aktivieren</td></tr><tr><td><code>DeviceFlag</code></td><td>Steuert, auf welchem Gerät Objekte sichtbar sind</td></tr><tr><td><code>LODGroup</code></td><td></td></tr><tr><td><code>ParticleSystem</code></td><td>Experimentell und derzeit nicht vollständig unterstützt</td></tr><tr><td><code>VideoPlayer</code></td><td>Wiedergabe von Videos von URL oder referenzierter Videodatei (wird beim Export in den Output kopiert). Der VideoPlayer unterstützt auch Streaming von MediaStream-Objekten oder <code>M3U8</code> Livestream-URLs</td></tr><tr><td><code>MeshRenderer</code></td><td>Wird zur Handhabung des Renderings von Objekten verwendet, einschließlich Lightmapping und Instancing</td></tr><tr><td><code>SkinnedMeshRenderer</code></td><td><em>Siehe MeshRenderer</em></td></tr><tr><td><code>SpriteRenderer</code></td><td>Wird zum Rendern von Sprites und Spriteanimationen verwendet</td></tr><tr><td><code>Volume</code> mit <code>PostProcessing</code> Asset</td><td>Siehe <a href="#postprocessing">Tabelle unten</a></td></tr></tbody></table><h3 id="nachbearbeitung" tabindex="-1"><a class="header-anchor" href="#nachbearbeitung"><span>Nachbearbeitung</span></a></h3><p>Nachbearbeitungseffekte verwenden im Hintergrund die <a href="https://www.npmjs.com/package/postprocessing" target="_blank" rel="noopener noreferrer">pmndrs postprocessing library</a>. Das bedeutet, Sie können auch einfach eigene Effekte hinzufügen und erhalten einen automatisch optimierten Nachbearbeitungsdurchgang.</p><ul><li><strong>Nur Unity</strong>: <em>Beachten Sie, dass Postprocessing-Effekte, die ein Volume in Unity verwenden, nur mit URP unterstützt werden.</em></li></ul><table><thead><tr><th>Effektname</th><th></th></tr></thead><tbody><tr><td>Antialiasing</td><td><em>zusätzliche Unity Komponente</em></td></tr><tr><td>Bloom</td><td><em>via Volume asset</em></td></tr><tr><td>Chromatic Aberration</td><td><em>via Volume asset</em></td></tr><tr><td>Color Adjustments / Color Correction</td><td><em>via Volume asset</em></td></tr><tr><td>Depth Of Field</td><td><em>via Volume asset</em></td></tr><tr><td>Vignette</td><td><em>via Volume asset</em></td></tr><tr><td>ToneMappingEffect</td><td><em>via Volume asset oder separate Komponente</em></td></tr><tr><td>Pixelation</td><td></td></tr><tr><td>Screenspace Ambient Occlusion N8</td><td></td></tr><tr><td>Screenspace Ambient Occlusion</td><td></td></tr><tr><td>Tilt Shift Effect</td><td></td></tr><tr><td>SharpeningEffect</td><td></td></tr><tr><td><em>Ihr eigener Effekt</em></td><td><a href="https://stackblitz.com/edit/needle-engine-custom-postprocessing-effect" target="_blank" rel="noopener noreferrer">Siehe Beispiel auf stackblitz</a></td></tr></tbody></table><h2 id="networking" tabindex="-1"><a class="header-anchor" href="#networking"><span>Networking</span></a></h2><table><thead><tr><th>Name</th><th>Beschreibung</th></tr></thead><tbody><tr><td><code>SyncedRoom</code></td><td>Haupt-Networking-Komponente. Platzieren Sie sie in Ihrer Szene, um Networking zu aktivieren</td></tr><tr><td><code>Networking</code></td><td>Wird zur Einrichtung des Backend-Servers für Networking verwendet.</td></tr><tr><td><code>SyncedTransform</code></td><td>Automatische Synchronisierung der Objekttransformation</td></tr><tr><td><code>SyncedCamera</code></td><td>Automatische Synchronisierung der Kameraposition und -ansicht für andere Benutzer im Raum. Sie können definieren, wie die Kamera gerendert wird, indem Sie ein Objekt referenzieren</td></tr><tr><td><code>WebXRSync</code></td><td>Synchronisiert WebXR-Avatare (AR und VR)</td></tr><tr><td><code>Voip</code></td><td>Ermöglicht Voice-Chat</td></tr><tr><td><code>Screensharing</code></td><td>Ermöglicht Screen-Sharing-Funktionen</td></tr></tbody></table><h2 id="interaktion" tabindex="-1"><a class="header-anchor" href="#interaktion"><span>Interaktion</span></a></h2><table><thead><tr><th>Name</th><th>Beschreibung</th></tr></thead><tbody><tr><td><code>EventSystem</code></td><td>Behandelt das Auslösen von Pointer- und UI-Events auf Objekten in der Szene</td></tr><tr><td><code>ObjectRaycater</code></td><td>Erforderlich für DragControls und Duplicatable</td></tr><tr><td><code>GraphicsRaycaster</code></td><td>Gleiches wie ObjectRaycater, aber für UI-Elemente</td></tr><tr><td><code>DragControls</code></td><td>Ermöglicht das Ziehen von Objekten in der Szene. Erfordert Raycaster in der Elternhierarchie, z.B. ObjectRaycater</td></tr><tr><td><code>Duplicatable</code></td><td>Kann zugewiesene Objekte durch Ziehen duplizieren. Erfordert DragControls</td></tr><tr><td><code>Interactable</code></td><td>Grundlegende Komponente zur Kennzeichnung eines Objekts als interaktionsfähig.</td></tr><tr><td><code>OrbitControls</code></td><td>Zur Kamera hinzufügen, um die Orbit-Steuerungsfunktionalität der Kamera hinzuzufügen</td></tr><tr><td><code>SmoothFollow</code></td><td>Ermöglicht die sanfte Interpolation zur Transformation eines anderen Objekts</td></tr><tr><td><code>DeleteBox</code></td><td>Zerstört Objekte mit der Komponente <code>Deletable</code>, wenn sie in die Box eintreten</td></tr><tr><td><code>Deletable</code></td><td>Das GameObject, an das diese Komponente angehängt ist, wird gelöscht, wenn es in eine <code>DeleteBox</code> eintritt oder sich mit ihr überschneidet</td></tr><tr><td><code>DropListener</code></td><td>Hinzufügen, um Datei-Drop-Events für den Upload zu empfangen</td></tr><tr><td><code>SpatialTrigger</code></td><td>Wird verwendet, um ein Event auszulösen, wenn ein Objekt einen bestimmten Raum oder Bereich betritt. Sie können auch Physik-Events verwenden</td></tr><tr><td><code>SpatialTriggerReceiver</code></td><td>Wird verwendet, um Events von SpatialTrigger zu empfangen</td></tr></tbody></table><h2 id="physik" tabindex="-1"><a class="header-anchor" href="#physik"><span>Physik</span></a></h2><p>Die Physik wird mit <a href="https://rapier.rs/" target="_blank" rel="noopener noreferrer">Rapier</a> implementiert.</p><table><thead><tr><th>Name</th><th>Beschreibung</th></tr></thead><tbody><tr><td><code>Rigidbody</code></td><td>Hinzufügen, um ein Objekt auf die Schwerkraft reagieren zu lassen (oder kinematisch und statisch zu sein)</td></tr><tr><td><code>BoxCollider</code></td><td>Eine Box-Collider-Form, mit der Objekte kollidieren oder Trigger-Events auslösen können, wenn sie auf <code>trigger</code> gesetzt ist</td></tr><tr><td><code>SphereCollider</code></td><td><em>Siehe BoxCollider</em></td></tr><tr><td><code>CapsuleCollider</code></td><td><em>Siehe BoxCollider</em></td></tr><tr><td><code>MeshCollider</code></td><td><em>Siehe BoxCollider</em></td></tr><tr><td>Physik-Materialien</td><td>Physik-Materialien können verwendet werden, um z. B. die Sprungkraft eines Colliders zu definieren</td></tr></tbody></table><h2 id="xr-webxr" tabindex="-1"><a class="header-anchor" href="#xr-webxr"><span>XR / WebXR</span></a></h2>',18)),e("p",null,[d(r,{to:"/lang/de/xr.html"},{default:i(()=>t[3]||(t[3]=[n("Lesen Sie die XR-Dokumentation")])),_:1})]),e("table",null,[t[15]||(t[15]=e("thead",null,[e("tr",null,[e("th",null,"Name"),e("th",null,"Beschreibung")])],-1)),e("tbody",null,[t[6]||(t[6]=e("tr",null,[e("td",null,[e("code",null,"WebXR")]),e("td",null,"Zur Szene hinzufügen für VR-, AR- und Passthrough-Unterstützung sowie zum Rendern von Avatar-Modellen")],-1)),e("tr",null,[e("td",null,[d(r,{to:"/lang/de/everywhere-actions.html"},{default:i(()=>t[4]||(t[4]=[e("code",null,"USDZExporter",-1)])),_:1})]),t[5]||(t[5]=e("td",null,"Hinzufügen, um USD und Quicklook-Unterstützung zu aktivieren",-1))]),t[7]||(t[7]=e("tr",null,[e("td",null,[e("code",null,"XRFlag")]),e("td",null,"Steuert, wann Objekte sichtbar sind, z. B. nur in VR oder AR oder nur in der Third-Person-Ansicht")],-1)),t[8]||(t[8]=e("tr",null,[e("td",null,[e("code",null,"WebARSessionRoot")]),e("td",null,"Handhabt die Platzierung und Skalierung Ihrer Szene im AR-Modus")],-1)),t[9]||(t[9]=e("tr",null,[e("td",null,[e("code",null,"WebARCameraBackground")]),e("td",null,"Hinzufügen, um auf das AR-Kamerabild zuzugreifen und Effekte anzuwenden oder es für das Rendering zu verwenden")],-1)),t[10]||(t[10]=e("tr",null,[e("td",null,[e("code",null,"WebXRImageTracking")]),e("td",null,"Bilder zur Verfolgung zuweisen und optional ein Objekt an der Bildposition instanziieren")],-1)),t[11]||(t[11]=e("tr",null,[e("td",null,[e("code",null,"WebXRPlaneTracking")]),e("td",null,"Planare Meshes oder Collider für verfolgte Ebenen erstellen")],-1)),t[12]||(t[12]=e("tr",null,[e("td",null,[e("code",null,"XRControllerModel")]),e("td",null,"Kann hinzugefügt werden, um Geräte-Controller oder Handmodelle zu rendern (werden standardmäßig erstellt, wenn in der WebXR-Komponente aktiviert)")],-1)),t[13]||(t[13]=e("tr",null,[e("td",null,[e("code",null,"XRControllerMovement")]),e("td",null,"Kann hinzugefügt werden, um Standardbewegungs- und Teleportationssteuerungen bereitzustellen")],-1)),t[14]||(t[14]=e("tr",null,[e("td",null,[e("code",null,"XRControllerFollow")]),e("td",null,"Kann zu jedem Objekt in der Szene hinzugefügt und so konfiguriert werden, dass es entweder der linken oder rechten Hand oder den Controllern folgt")],-1))])]),t[21]||(t[21]=o('<h2 id="debugging" tabindex="-1"><a class="header-anchor" href="#debugging"><span>Debugging</span></a></h2><table><thead><tr><th>Name</th><th>Beschreibung</th></tr></thead><tbody><tr><td><code>GridHelper</code></td><td>Zeichnet ein Gitter</td></tr><tr><td><code>BoxGizmo</code></td><td>Zeichnet eine Box</td></tr><tr><td><code>AxesHelper</code></td><td>Zeichnet XYZ-Achsen</td></tr><tr><td></td><td>Hinweis: Wenn Sie benutzerdefinierten Code schreiben, können Sie die statischen <code>Gizmos</code>-Methoden zum Zeichnen von Debugging-Linien und -Formen verwenden</td></tr></tbody></table><h2 id="laufzeit-datei-input-output" tabindex="-1"><a class="header-anchor" href="#laufzeit-datei-input-output"><span>Laufzeit-Datei-Input/Output</span></a></h2><table><thead><tr><th>Name</th><th>Beschreibung</th></tr></thead><tbody><tr><td><code>GltfExport</code></td><td>Experimentell! Wird zum Exportieren von gltf aus der Web-Laufzeit verwendet.</td></tr><tr><td><code>DropListener</code></td><td>Empfängt Datei-Drop-Events für den Upload und Networking</td></tr></tbody></table><h2 id="ui" tabindex="-1"><a class="header-anchor" href="#ui"><span>UI</span></a></h2><p>Räumliche UI-Komponenten werden von Unity UI (Canvas, nicht UI Toolkit) auf <a href="https://github.com/felixmariotto/three-mesh-ui" target="_blank" rel="noopener noreferrer">three-mesh-ui</a> abgebildet. UI kann animiert werden.</p><table><thead><tr><th>Name</th><th>Beschreibung</th></tr></thead><tbody><tr><td><code>Canvas</code></td><td>Unitys UI-System. Muss derzeit im World Space Modus sein.</td></tr><tr><td><code>Text (Legacy)</code></td><td>Rendert Text mit Unitys UI Text-Komponente. Benutzerdefinierte Schriftarten werden unterstützt, ein Schriftart-Atlas wird beim Export automatisch generiert. Verwenden Sie die Schriftart-Einstellungen oder die <code>FontAdditionalCharacters</code>-Komponente, um zu steuern, welche Zeichen in den Atlas aufgenommen werden.<br><strong>Hinweis</strong>: Stellen Sie in Unity sicher, dass Sie die Komponente <code>Legacy/Text</code> verwenden (<em>TextMeshPro</em> wird derzeit nicht unterstützt)</td></tr><tr><td><code>Button</code></td><td>Empfängt Klick-Events - verwenden Sie das onClick-Event, um darauf zu reagieren. Es kann auch zu 3D-Szenenobjekten hinzugefügt werden.<br><strong>Hinweis</strong>: Stellen Sie sicher, dass Sie die Komponente <code>Legacy/Text</code> im Button verwenden (oder erstellen Sie den Button über das Kontextmenü <code>UI/Legacy/Button</code> in Unity, da <em>TextMeshPro</em> derzeit nicht unterstützt wird)</td></tr><tr><td><code>Image</code></td><td>Rendert ein Sprite-Bild</td></tr><tr><td><code>RawImage</code></td><td>Rendert eine Textur</td></tr><tr><td><code>InputField</code></td><td>Ermöglicht Texteingabe</td></tr></tbody></table><p><strong>Hinweis</strong>: Je nach Projekt ist oft eine Mischung aus räumlicher und 2D-UI sinnvoll für Cross-Platform-Projekte, bei denen VR, AR und Bildschirme unterstützt werden. Typischerweise würden Sie die 2D-Teile mit HTML für beste Zugänglichkeit erstellen und die 3D-Teile mit geometrischen UIs, die auch Tiefen-Offsets unterstützen (z. B. Button-Hover-States und ähnliches).</p><h2 id="sonstiges" tabindex="-1"><a class="header-anchor" href="#sonstiges"><span>Sonstiges</span></a></h2><table><thead><tr><th>Name</th><th>Beschreibung</th></tr></thead><tbody><tr><td><code>SceneSwitcher</code></td><td>Handhabt das Laden und Entladen anderer Szenen oder Prefabs / glTF-Dateien. Verfügt über Funktionen zum Vorladen, Wechseln von Szenen durch Wischen, Tastatur-Events oder URL-Navigation</td></tr></tbody></table><h2 id="nur-editor" tabindex="-1"><a class="header-anchor" href="#nur-editor"><span>Nur Editor</span></a></h2><table><thead><tr><th>Name</th><th>Beschreibung</th></tr></thead><tbody><tr><td><code>ExportInfo</code></td><td>Hauptkomponente zur Verwaltung des/der Webprojekts/e, z. B. zum Installieren oder Starten der Web-App</td></tr><tr><td><code>EditorSync</code></td><td>Hinzufügen, um die Netzwerk-Synchronisierung von Material- oder Komponentenwertänderungen direkt vom Unity Editor zur laufenden three.js-App zu ermöglichen, ohne neu laden zu müssen</td></tr><tr><td>Seite automatisch mit AI übersetzt</td><td></td></tr></tbody></table>',12))])}const b=a(h,[["render",c]]),p=JSON.parse('{"path":"/lang/de/component-reference.html","title":"Needle-Kernkomponenten","lang":"de-DE","frontmatter":{"title":"Needle-Kernkomponenten","head":[["meta",{"name":"og:image","content":"https://engine.needle.tools/docs/.preview/needle kernkomponenten_de.png"}],["meta",{"name":"og:description","content":"---\\nHier ist eine Übersicht über einige der von uns bereitgestellten Komponenten. Viele davon bilden Komponenten und Funktionen in Unity, Blender oder anderen Integrationen ab.\\nEine vollständige Liste finden Sie in unserer API-Dokumentation.\\nSie können jederzeit eigene Komponenten hinzufügen oder Wrapper für Unity-Komponenten erstellen, die wir noch nicht bereitgestellt haben.\\nMehr dazu erfahren Sie im Abschnitt Skripting unserer Dokumentation."}]],"description":"---\\nHier ist eine Übersicht über einige der von uns bereitgestellten Komponenten. Viele davon bilden Komponenten und Funktionen in Unity, Blender oder anderen Integrationen ab.\\nEine vollständige Liste finden Sie in unserer API-Dokumentation.\\nSie können jederzeit eigene Komponenten hinzufügen oder Wrapper für Unity-Komponenten erstellen, die wir noch nicht bereitgestellt haben.\\nMehr dazu erfahren Sie im Abschnitt Skripting unserer Dokumentation."},"headers":[{"level":2,"title":"Audio","slug":"audio","link":"#audio","children":[]},{"level":2,"title":"Animation","slug":"animation","link":"#animation","children":[]},{"level":2,"title":"Rendering","slug":"rendering","link":"#rendering","children":[{"level":3,"title":"Nachbearbeitung","slug":"nachbearbeitung","link":"#nachbearbeitung","children":[]}]},{"level":2,"title":"Networking","slug":"networking","link":"#networking","children":[]},{"level":2,"title":"Interaktion","slug":"interaktion","link":"#interaktion","children":[]},{"level":2,"title":"Physik","slug":"physik","link":"#physik","children":[]},{"level":2,"title":"XR / WebXR","slug":"xr-webxr","link":"#xr-webxr","children":[]},{"level":2,"title":"Debugging","slug":"debugging","link":"#debugging","children":[]},{"level":2,"title":"Laufzeit-Datei-Input/Output","slug":"laufzeit-datei-input-output","link":"#laufzeit-datei-input-output","children":[]},{"level":2,"title":"UI","slug":"ui","link":"#ui","children":[]},{"level":2,"title":"Sonstiges","slug":"sonstiges","link":"#sonstiges","children":[]},{"level":2,"title":"Nur Editor","slug":"nur-editor","link":"#nur-editor","children":[]}],"git":{"updatedTime":1745311490000,"contributors":[{"name":"Marcel Wiessler","username":"","email":"marcel@gaisterhand.de","commits":1}],"changelog":[{"hash":"25e22e2b0b9e4fc1e515be2b189c24864e21ac9f","time":1745311490000,"email":"marcel@gaisterhand.de","author":"Marcel Wiessler","message":"add multilanguage support"}]},"filePathRelative":"lang/de/component-reference.md"}');export{b as comp,p as data};
