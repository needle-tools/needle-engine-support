import{_ as i,c as a,a as t,e as l,d,b as o,w as n,r as s,o as c}from"./app-9T6lAodh.js";const h={};function p(u,e){const r=s("RouteLink");return c(),a("div",null,[e[16]||(e[16]=t("h1",{id:"needle",tabindex:"-1"},[t("a",{class:"header-anchor",href:"#needle"},[t("span",null,"Needle 核心组件")])],-1)),e[17]||(e[17]=t("p",null,"以下是我们提供的一些组件概述。其中许多组件映射到 Unity、Blender 或其他集成中的组件和功能。",-1)),e[18]||(e[18]=t("p",null,[d("如需完整列表，请参阅我们的 "),t("a",{href:"https://engine.needle.tools/docs/api/latest",target:"_blank",rel:"noopener noreferrer"},"API 文档"),d("。")],-1)),e[19]||(e[19]=t("p",null,"您随时可以添加自己的组件，或者为我们尚未提供的 Unity 组件添加包装器。",-1)),t("p",null,[e[1]||(e[1]=d("在我们的文档的 ")),o(r,{to:"/lang/zh/scripting.html"},{default:n(()=>e[0]||(e[0]=[d("Scripting")])),_:1}),e[2]||(e[2]=d(" 部分了解更多信息。"))]),e[20]||(e[20]=l('<h2 id="audio" tabindex="-1"><a class="header-anchor" href="#audio"><span>Audio</span></a></h2><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><code>AudioListener</code></td><td></td></tr><tr><td><code>AudioSource</code></td><td>用于播放音频</td></tr></tbody></table><h2 id="animation" tabindex="-1"><a class="header-anchor" href="#animation"><span>Animation</span></a></h2><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><code>Animator</code> with <code>AnimatorController</code></td><td>导出动画状态机、条件、过渡</td></tr><tr><td><code>Animation</code></td><td>最基本的动画组件。仅导出第一个剪辑</td></tr><tr><td><code>PlayableDirector</code> with <code>TimelineAsset</code></td><td>导出强大的序列以控制动画、音频、状态等</td></tr></tbody></table><h2 id="rendering" tabindex="-1"><a class="header-anchor" href="#rendering"><span>Rendering</span></a></h2><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><code>Camera</code></td><td></td></tr><tr><td><code>Light</code></td><td>DirectionalLight, PointLight, Spotlight。请注意，您也可以使用它来烘焙光照（例如 Rectangular Light 形状）</td></tr><tr><td><code>XRFlag</code></td><td>控制对象何时可见。例如，仅在 AR 中启用对象</td></tr><tr><td><code>DeviceFlag</code></td><td>控制对象在哪种设备上可见</td></tr><tr><td><code>LODGroup</code></td><td></td></tr><tr><td><code>ParticleSystem</code></td><td>实验性功能，目前未完全支持</td></tr><tr><td><code>VideoPlayer</code></td><td>播放来自 URL 或引用的视频文件（导出时将复制到输出）的视频。VideoPlayer 还支持从 MediaStream 对象或 <code>M3U8</code> 直播 URL 进行流式传输</td></tr><tr><td><code>MeshRenderer</code></td><td>用于处理对象的渲染，包括光照贴图和实例化</td></tr><tr><td><code>SkinnedMeshRenderer</code></td><td><em>参见 MeshRenderer</em></td></tr><tr><td><code>SpriteRenderer</code></td><td>用于渲染 Sprites 和 Spriteanimations</td></tr><tr><td><code>Volume</code> with <code>PostProcessing</code> asset</td><td>参见<a href="#postprocessing">下表</a></td></tr></tbody></table><h3 id="postprocessing" tabindex="-1"><a class="header-anchor" href="#postprocessing"><span>Postprocessing</span></a></h3><p>后处理效果在底层使用了 <a href="https://www.npmjs.com/package/postprocessing" target="_blank" rel="noopener noreferrer">pmndrs postprocessing library</a>。这意味着您也可以轻松添加自己的自定义效果，并获得自动优化的后处理通道。</p><ul><li><strong>仅 Unity</strong>: <em>请注意，在 Unity 中使用 Volume 的后处理效果仅支持 URP</em></li></ul><table><thead><tr><th>Effect Name</th><th></th></tr></thead><tbody><tr><td>Antialiasing</td><td><em>额外 Unity 组件</em></td></tr><tr><td>Bloom</td><td><em>通过 Volume asset</em></td></tr><tr><td>Chromatic Aberration</td><td><em>通过 Volume asset</em></td></tr><tr><td>Color Adjustments / Color Correction</td><td><em>通过 Volume asset</em></td></tr><tr><td>Depth Of Field</td><td><em>通过 Volume asset</em></td></tr><tr><td>Vignette</td><td><em>通过 Volume asset</em></td></tr><tr><td>ToneMappingEffect</td><td><em>通过 Volume asset 或单独组件</em></td></tr><tr><td>Pixelation</td><td></td></tr><tr><td>Screenspace Ambient Occlusion N8</td><td></td></tr><tr><td>Screenspace Ambient Occlusion</td><td></td></tr><tr><td>Tilt Shift Effect</td><td></td></tr><tr><td>SharpeningEffect</td><td></td></tr><tr><td><em>Your custom effect</em></td><td><a href="https://stackblitz.com/edit/needle-engine-custom-postprocessing-effect" target="_blank" rel="noopener noreferrer">参见 stackblitz 示例</a></td></tr></tbody></table><h2 id="networking" tabindex="-1"><a class="header-anchor" href="#networking"><span>Networking</span></a></h2><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><code>SyncedRoom</code></td><td>主要网络组件。添加到场景中即可启用网络功能</td></tr><tr><td><code>Networking</code></td><td>用于设置网络的后端服务器</td></tr><tr><td><code>SyncedTransform</code></td><td>自动同步对象的变换</td></tr><tr><td><code>SyncedCamera</code></td><td>自动向房间中的其他用户同步摄像头位置和视图。您可以通过引用一个对象来定义摄像头的渲染方式</td></tr><tr><td><code>WebXRSync</code></td><td>同步 WebXR Avatar（AR 和 VR）</td></tr><tr><td><code>Voip</code></td><td>启用语音聊天</td></tr><tr><td><code>Screensharing</code></td><td>启用屏幕共享功能</td></tr></tbody></table><h2 id="interaction" tabindex="-1"><a class="header-anchor" href="#interaction"><span>Interaction</span></a></h2><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><code>EventSystem</code></td><td>处理在场景对象上触发指针事件和 UI 事件</td></tr><tr><td><code>ObjectRaycater</code></td><td>DragControls 和 Duplicatable 所需</td></tr><tr><td><code>GraphicsRaycaster</code></td><td>与 ObjectRaycaster 相同，但用于 UI 元素</td></tr><tr><td><code>DragControls</code></td><td>允许在场景中拖动对象。需要在父级层级中存在 raycaster，例如 ObjectRaycaster</td></tr><tr><td><code>Duplicatable</code></td><td>可以通过拖动复制指定的对象。需要 DragControls</td></tr><tr><td><code>Interactable</code></td><td>将对象标记为可交互的基本组件</td></tr><tr><td><code>OrbitControls</code></td><td>添加到摄像头以添加摄像头轨道控制功能</td></tr><tr><td><code>SmoothFollow</code></td><td>允许平滑地插值到另一个对象的变换</td></tr><tr><td><code>DeleteBox</code></td><td>进入此框的对象（带有 <code>Deletable</code> 组件）将被销毁</td></tr><tr><td><code>Deletable</code></td><td>附加此组件的 GameObject 在进入或与 <code>DeleteBox</code> 相交时将被删除</td></tr><tr><td><code>DropListener</code></td><td>添加以接收文件拖放事件进行上传</td></tr><tr><td><code>SpatialTrigger</code></td><td>用于在对象进入特定空间或区域时触发事件。您也可以使用 Physics 事件</td></tr><tr><td><code>SpatialTriggerReceiver</code></td><td>用于接收 SpatialTrigger 发送的事件</td></tr></tbody></table><h2 id="physics" tabindex="-1"><a class="header-anchor" href="#physics"><span>Physics</span></a></h2><p>物理引擎使用 <a href="https://rapier.rs/" target="_blank" rel="noopener noreferrer">Rapier</a> 实现。</p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><code>Rigidbody</code></td><td>添加以使对象响应重力（或设置为 kinematic 和 static）</td></tr><tr><td><code>BoxCollider</code></td><td>一个 Box 碰撞体形状，对象可以与之碰撞，或者在设置为 <code>trigger</code> 时触发事件</td></tr><tr><td><code>SphereCollider</code></td><td><em>参见 BoxCollider</em></td></tr><tr><td><code>CapsuleCollider</code></td><td><em>参见 BoxCollider</em></td></tr><tr><td><code>MeshCollider</code></td><td><em>参见 BoxCollider</em></td></tr><tr><td>Physics Materials</td><td>Physics materials 可用于定义碰撞体的弹性等属性</td></tr></tbody></table><h2 id="xr-webxr" tabindex="-1"><a class="header-anchor" href="#xr-webxr"><span>XR / WebXR</span></a></h2>',18)),t("p",null,[o(r,{to:"/lang/zh/xr.html"},{default:n(()=>e[3]||(e[3]=[d("阅读 XR 文档")])),_:1})]),t("table",null,[e[15]||(e[15]=t("thead",null,[t("tr",null,[t("th",null,"Name"),t("th",null,"Description")])],-1)),t("tbody",null,[e[6]||(e[6]=t("tr",null,[t("td",null,[t("code",null,"WebXR")]),t("td",null,"添加到场景中以支持 VR、AR 和 Passthrough，以及渲染 Avatar 模型")],-1)),t("tr",null,[t("td",null,[o(r,{to:"/lang/zh/everywhere-actions.html"},{default:n(()=>e[4]||(e[4]=[t("code",null,"USDZExporter",-1)])),_:1})]),e[5]||(e[5]=t("td",null,"添加以启用 USD 和 Quicklook 支持",-1))]),e[7]||(e[7]=t("tr",null,[t("td",null,[t("code",null,"XRFlag")]),t("td",null,"控制对象何时可见，例如，仅在 VR 或 AR 中，或仅在第三人称视图中")],-1)),e[8]||(e[8]=t("tr",null,[t("td",null,[t("code",null,"WebARSessionRoot")]),t("td",null,"处理场景在 AR 模式下的放置和缩放")],-1)),e[9]||(e[9]=t("tr",null,[t("td",null,[t("code",null,"WebARCameraBackground")]),t("td",null,"添加以访问 AR 摄像头图像并应用效果或用于渲染")],-1)),e[10]||(e[10]=t("tr",null,[t("td",null,[t("code",null,"WebXRImageTracking")]),t("td",null,"分配要跟踪的图像，并可选择在图像位置实例化对象")],-1)),e[11]||(e[11]=t("tr",null,[t("td",null,[t("code",null,"WebXRPlaneTracking")]),t("td",null,"为跟踪到的平面创建平面网格或碰撞体")],-1)),e[12]||(e[12]=t("tr",null,[t("td",null,[t("code",null,"XRControllerModel")]),t("td",null,"可以添加到渲染设备控制器或手部模型（在 WebXR 组件中启用时会默认创建）")],-1)),e[13]||(e[13]=t("tr",null,[t("td",null,[t("code",null,"XRControllerMovement")]),t("td",null,"可以添加以提供默认的移动和传送控制")],-1)),e[14]||(e[14]=t("tr",null,[t("td",null,[t("code",null,"XRControllerFollow")]),t("td",null,"可以添加到场景中的任何对象，并配置为跟随左手或右手或控制器")],-1))])]),e[21]||(e[21]=l('<h2 id="debugging" tabindex="-1"><a class="header-anchor" href="#debugging"><span>Debugging</span></a></h2><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><code>GridHelper</code></td><td>绘制网格</td></tr><tr><td><code>BoxGizmo</code></td><td>绘制盒子</td></tr><tr><td><code>AxesHelper</code></td><td>绘制 XYZ 轴</td></tr><tr><td></td><td>注意：当您编写自定义代码时，可以使用静态 <code>Gizmos</code> 方法绘制调试线条和形状</td></tr></tbody></table><h2 id="runtime-file-input-output" tabindex="-1"><a class="header-anchor" href="#runtime-file-input-output"><span>Runtime File Input/Output</span></a></h2><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><code>GltfExport</code></td><td>实验性功能！用于从 Web 运行时导出 gltf。</td></tr><tr><td><code>DropListener</code></td><td>接收文件拖放事件用于上传和网络</td></tr></tbody></table><h2 id="ui" tabindex="-1"><a class="header-anchor" href="#ui"><span>UI</span></a></h2><p>空间 UI 组件从 Unity UI（Canvas，非 UI Toolkit）映射到 <a href="https://github.com/felixmariotto/three-mesh-ui" target="_blank" rel="noopener noreferrer">three-mesh-ui</a>。 UI 可以动画化。</p><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><code>Canvas</code></td><td>Unity 的 UI 系统。目前需要处于 World Space 模式。</td></tr><tr><td><code>Text (Legacy)</code></td><td>使用 Unity 的 UI Text 组件渲染文本。支持自定义字体，导出时会自动生成字体图集。使用字体设置或 <code>FontAdditionalCharacters</code> 组件控制图集中包含哪些字符。<br><strong>注意</strong>：在 Unity 中请确保使用 <code>Legacy/Text</code> 组件（目前不支持 <em>TextMeshPro</em>）</td></tr><tr><td><code>Button</code></td><td>接收点击事件 - 使用 onClick 事件进行响应。也可以添加到 3D 场景对象。<br><strong>注意</strong>：请确保在 Button 中使用 <code>Legacy/Text</code> 组件（或通过 <code>UI/Legacy/Button</code> Unity 上下文菜单创建 Button，因为目前不支持 <em>TextMeshPro</em>）</td></tr><tr><td><code>Image</code></td><td>渲染精灵图像</td></tr><tr><td><code>RawImage</code></td><td>渲染纹理</td></tr><tr><td><code>InputField</code></td><td>允许文本输入</td></tr></tbody></table><p><strong>注意</strong>：根据您的项目，对于支持 VR、AR 和屏幕的跨平台项目，通常空间 UI 和 2D UI 的混合使用是有意义的。通常，您会使用 HTML 构建 2D 部分以获得最佳可访问性，并使用支持深度偏移（例如按钮悬停状态等）的几何 UI 构建 3D 部分。</p><h2 id="other" tabindex="-1"><a class="header-anchor" href="#other"><span>Other</span></a></h2><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><code>SceneSwitcher</code></td><td>处理其他场景或预制件/glTF 文件的加载和卸载。具有预加载、通过滑动、键盘事件或 URL 导航切换场景的功能</td></tr></tbody></table><h2 id="editor-only" tabindex="-1"><a class="header-anchor" href="#editor-only"><span>Editor Only</span></a></h2><table><thead><tr><th>Name</th><th>Description</th></tr></thead><tbody><tr><td><code>ExportInfo</code></td><td>用于管理 Web 项目（例如安装或启动 Web 应用）的主要组件</td></tr><tr><td><code>EditorSync</code></td><td>添加此组件可直接从 Unity Editor 同步材质或组件值更改到正在运行的 three.js 应用，无需重新加载</td></tr></tbody></table><hr><p>页面由 AI 自动翻译</p>',14))])}const g=i(h,[["render",p]]),b=JSON.parse('{"path":"/lang/zh/component-reference.html","title":"Needle 核心组件","lang":"zh-CN","frontmatter":{"title":"Needle 核心组件","head":[["meta",{"name":"og:image","content":"https://engine.needle.tools/docs/.preview/needle_zh.png"}],["meta",{"name":"og:description","content":"---\\n以下是我们提供的一些组件概述。其中许多组件映射到 Unity、Blender 或其他集成中的组件和功能。\\n如需完整列表，请参阅我们的 API 文档。\\n您随时可以添加自己的组件，或者为我们尚未提供的 Unity 组件添加包装器。\\n在我们的文档的 Scripting 部分了解更多信息。"}]],"description":"---\\n以下是我们提供的一些组件概述。其中许多组件映射到 Unity、Blender 或其他集成中的组件和功能。\\n如需完整列表，请参阅我们的 API 文档。\\n您随时可以添加自己的组件，或者为我们尚未提供的 Unity 组件添加包装器。\\n在我们的文档的 Scripting 部分了解更多信息。"},"headers":[{"level":2,"title":"Audio","slug":"audio","link":"#audio","children":[]},{"level":2,"title":"Animation","slug":"animation","link":"#animation","children":[]},{"level":2,"title":"Rendering","slug":"rendering","link":"#rendering","children":[{"level":3,"title":"Postprocessing","slug":"postprocessing","link":"#postprocessing","children":[]}]},{"level":2,"title":"Networking","slug":"networking","link":"#networking","children":[]},{"level":2,"title":"Interaction","slug":"interaction","link":"#interaction","children":[]},{"level":2,"title":"Physics","slug":"physics","link":"#physics","children":[]},{"level":2,"title":"XR / WebXR","slug":"xr-webxr","link":"#xr-webxr","children":[]},{"level":2,"title":"Debugging","slug":"debugging","link":"#debugging","children":[]},{"level":2,"title":"Runtime File Input/Output","slug":"runtime-file-input-output","link":"#runtime-file-input-output","children":[]},{"level":2,"title":"UI","slug":"ui","link":"#ui","children":[]},{"level":2,"title":"Other","slug":"other","link":"#other","children":[]},{"level":2,"title":"Editor Only","slug":"editor-only","link":"#editor-only","children":[]}],"git":{"updatedTime":1745311490000,"contributors":[{"name":"Marcel Wiessler","username":"","email":"marcel@gaisterhand.de","commits":1}],"changelog":[{"hash":"25e22e2b0b9e4fc1e515be2b189c24864e21ac9f","time":1745311490000,"email":"marcel@gaisterhand.de","author":"Marcel Wiessler","message":"add multilanguage support"}]},"filePathRelative":"lang/zh/component-reference.md"}');export{g as comp,b as data};
