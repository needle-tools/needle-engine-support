import{_ as d,c as u,a as n,e as l,b as t,d as i,w as s,r as o,o as h}from"./app-9T6lAodh.js";const p={},g={class:"hint-container tip"};function k(m,e){const r=o("RouteLink"),a=o("sample");return h(),u("div",null,[e[40]||(e[40]=n("h2",{id:"unterst-tzte-ger-te",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#unterst-tzte-ger-te"},[n("span",null,"Unterstützte Geräte")])],-1)),e[41]||(e[41]=n("p",null,[i("Needle Engine unterstützt die vollständige "),n("a",{href:"https://developer.mozilla.org/en-US/docs/Web/API/WebXR_Device_API",target:"_blank",rel:"noopener noreferrer"},"WebXR-Spezifikation"),i(", einschließlich AR und VR. WebXR ist ein offizieller Webstandard, der immersive Erlebnisse ins Web bringt, mit allen Vorteilen des Webs: keine Installation, kein App Store, keine SDKs erforderlich.")],-1)),e[42]||(e[42]=n("p",null,"Alle Geräte mit einem Browser können mit Needle erstellte Apps ausführen. Wenn der Browser WebXR unterstützt, funktionieren Ihre Apps automatisch auch in XR, indem sie unsere integrierten Komponenten verwenden. Dazu gehören Desktop-Browser, mobile Browser, viele Browser auf AR/VR-Headsets, aber auch andere aufkommende Technologien wie Looking Glass-Displays, Smart Glasses und mehr.",-1)),n("div",g,[e[5]||(e[5]=n("p",{class:"hint-container-title"},"App-freie iOS AR-Unterstützung über USDZ/QuickLook",-1)),n("p",null,[e[1]||(e[1]=i("Während iOS-Geräte noch keine offizielle WebXR-Unterstützung bieten, unterstützt Needle die Erstellung von AR-Erlebnissen auf iOS mithilfe von ")),t(r,{to:"/lang/de/everywhere-actions.html"},{default:s(()=>e[0]||(e[0]=[i("Everywhere Actions")])),_:1}),e[2]||(e[2]=i(". Weitere Details finden Sie im ")),e[3]||(e[3]=n("a",{href:"#augmented-reality-and-webxr-on-ios"},"iOS-Abschnitt",-1)),e[4]||(e[4]=i(". Sie können reichhaltige, interaktive Erlebnisse erstellen, die nahtlos in AR auf iOS-Geräten funktionieren, selbst mit den Einschränkungen, die Apple festgelegt hat."))]),e[6]||(e[6]=n("p",null,"Wenn Sie den AR-Modus auf iOS aufrufen, konvertiert Needle Ihre Szene automatisch in eine USDZ-Datei, die dann in AR mithilfe von Apples QuickLook angezeigt wird. Objekte, Materialien, Audio, Animationen und Everywhere Actions bleiben erhalten.",-1))]),e[43]||(e[43]=l("<p>Die folgende Tabelle listet einige der Geräte auf, die wir erfolgreich mit Needle Engine getestet haben. Wenn ein neues Gerät auf den Markt kommt, das WebXR unterstützt, funktioniert es ohne weiteres mit Ihren Apps. Dies ist einer der großen Vorteile der Entwicklung mit dem Browser als Plattform – die Kompatibilität ist nicht auf eine bestimmte Gruppe von Geräten oder SDKs beschränkt.</p><table><thead><tr><th>Headset-Gerät</th><th>Browser</th><th>Hinweise</th></tr></thead><tbody><tr><td>Apple Vision Pro</td><td>✔️ Safari</td><td>Hand-Tracking, Unterstützung für transienten Pointer</td></tr><tr><td>Meta Quest 3</td><td>✔️ Meta Browser</td><td>Hand-Tracking, Unterstützung für sessiongranted<sup>1</sup>, Passthrough, Tiefenmessung, Mesh-Tracking</td></tr><tr><td>Meta Quest 3S</td><td>✔️ Meta Browser</td><td>Hand-Tracking, Unterstützung für sessiongranted<sup>1</sup>, Passthrough, Tiefenmessung, Mesh-Tracking</td></tr><tr><td>Meta Quest 2</td><td>✔️ Meta Browser</td><td>Hand-Tracking, Unterstützung für sessiongranted<sup>1</sup>, Passthrough (Schwarz-Weiß)</td></tr><tr><td>Meta Quest 1</td><td>✔️ Meta Browser</td><td>Hand-Tracking, Unterstützung für sessiongranted<sup>1</sup></td></tr><tr><td>Meta Quest Pro</td><td>✔️ Meta Browser</td><td>Hand-Tracking, Unterstützung für sessiongranted<sup>1</sup>, Passthrough</td></tr><tr><td>Pico Neo 4</td><td>✔️ Pico Browser</td><td>Passthrough, Hand-Tracking<sup>2</sup></td></tr><tr><td>Pico Neo 3</td><td>✔️ Pico Browser</td><td>kein Hand-Tracking, invertierte Controller-Thumbsticks</td></tr><tr><td>Oculus Rift 1/2</td><td>✔️ Chrome</td><td></td></tr><tr><td>Valve Index</td><td>✔️ Chrome</td><td></td></tr><tr><td>HTC Vive</td><td>✔️ Chrome</td><td></td></tr><tr><td>Hololens 2</td><td>✔️ Edge</td><td>Hand-Tracking, Unterstützung für AR und VR (im VR-Modus wird der Hintergrund ebenfalls gerendert)</td></tr></tbody></table>",2)),n("table",null,[e[19]||(e[19]=n("thead",null,[n("tr",null,[n("th",null,"Mobilgerät"),n("th",null,"Browser"),n("th",null,"Hinweise")])],-1)),n("tbody",null,[e[12]||(e[12]=n("tr",null,[n("td",null,"Android 10+"),n("td",null,"✔️ Chrome"),n("td")],-1)),e[13]||(e[13]=n("tr",null,[n("td",null,"Android 10+"),n("td",null,"✔️ Firefox"),n("td")],-1)),n("tr",null,[e[10]||(e[10]=n("td",null,"iOS 15+",-1)),e[11]||(e[11]=n("td",null,[i("(✔️)"),n("sup",null,"3"),i(" Safari"),n("br"),i("(✔️)"),n("sup",null,"3"),i(" Chrome")],-1)),n("td",null,[e[8]||(e[8]=i("Keine vollständige Code-Unterstützung, aber Needle ")),t(r,{to:"/lang/de/everywhere-actions.html"},{default:s(()=>e[7]||(e[7]=[i("Everywhere Actions")])),_:1}),e[9]||(e[9]=i(" werden zur Erstellung dynamischer, interaktiver USDZ-Dateien unterstützt."))])]),e[14]||(e[14]=n("tr",null,[n("td",null,"iOS 15+"),n("td",null,"✔️ WebXR Viewer"),n("td",null,"Browser ist inzwischen etwas veraltet")],-1)),e[15]||(e[15]=n("tr",null,[n("td",null,"Hololens 2"),n("td",null,"✔️ Edge"),n("td")],-1)),e[16]||(e[16]=n("tr",null,[n("td",null,"Hololens 1"),n("td",null,"❌"),n("td",null,"keine WebXR-Unterstützung")],-1)),e[17]||(e[17]=n("tr",null,[n("td",null,"Magic Leap 2"),n("td",null,"✔️"),n("td")],-1)),e[18]||(e[18]=n("tr",null,[n("td",null,"Magic Leap 1"),n("td",null,"✔️"),n("td",null,"veraltetes Gerät")],-1))])]),e[44]||(e[44]=l('<table><thead><tr><th>Andere Geräte</th><th>Browser</th><th>Hinweise</th></tr></thead><tbody><tr><td>Looking Glass Holographic Display</td><td>✔️ Chrome</td><td>erfordert Looking Glass Bridge und etwas eigenen Code, <a href="https://engine.needle.tools/samples/looking-glass/" target="_blank" rel="noopener noreferrer">siehe unser Beispiel</a></td></tr><tr><td>Logitech MX Ink</td><td>✔️ Meta Browser</td><td>offiziell unterstützt, siehe <a href="https://logitech.github.io/mxink/WebXR/WebXrIntegration.html#using-needle-tools" target="_blank" rel="noopener noreferrer">Dokumentation</a></td></tr></tbody></table>',1)),n("p",null,[e[21]||(e[21]=n("sup",null,"1",-1)),e[22]||(e[22]=i(": Erfordert die Aktivierung eines Browser-Flags: ")),e[23]||(e[23]=n("code",null,"chrome://flags/#webxr-navigation-permission",-1)),e[24]||(e[24]=n("sup",null,"2",-1)),e[25]||(e[25]=i(": Erfordert die Aktivierung einer Einstellung in den Entwickleroptionen ")),e[26]||(e[26]=n("sup",null,"3",-1)),e[27]||(e[27]=i(": Verwendet ")),t(r,{to:"/lang/de/everywhere-actions.html"},{default:s(()=>e[20]||(e[20]=[i("Everywhere Actions")])),_:1}),e[28]||(e[28]=i(" oder ")),e[29]||(e[29]=n("a",{href:"#augmented-reality-and-webxr-on-ios"},"andere Ansätze",-1))]),e[45]||(e[45]=n("h2",{id:"vr-ar-und-quicklook-beispiele",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#vr-ar-und-quicklook-beispiele"},[n("span",null,"VR-, AR- und QuickLook-Beispiele")])],-1)),e[46]||(e[46]=n("p",null,[i("Besuchen Sie unsere "),n("a",{href:"https://engine.needle.tools/samples/?overlay=samples&tag=xr",target:"_blank",rel:"noopener noreferrer"},"Needle Engine Samples"),i(", um viele interaktive Beispiele sofort auszuprobieren. Oder testen Sie es live auf Ihrem Gerät, indem Sie auf die Schaltflächen "),n("kbd",null,"QR-Code"),i(" (für Telefone) oder "),n("kbd",null,"Auf Quest öffnen"),i(" (für Meta Quest-Headsets) unten klicken.")],-1)),t(a,{src:"https://engine.needle.tools/samples/collaborative-sandbox/"}),e[47]||(e[47]=l('<h2 id="hinzuf-gen-von-vr-und-ar-funktionen-zu-einer-szene" tabindex="-1"><a class="header-anchor" href="#hinzuf-gen-von-vr-und-ar-funktionen-zu-einer-szene"><span>Hinzufügen von VR- und AR-Funktionen zu einer Szene</span></a></h2><p>AR-, VR- und Netzwerkfähigkeiten in Needle Engine sind modular aufgebaut. Sie können wählen, ob Sie keine davon unterstützen oder nur bestimmte Funktionen hinzufügen möchten.</p><h3 id="grundfunktionen" tabindex="-1"><a class="header-anchor" href="#grundfunktionen"><span>Grundfunktionen</span></a></h3><ol><li><p><strong>AR und VR aktivieren</strong> Fügen Sie eine <code>WebXR</code>-Komponente hinzu. <em>Optional:</em> Sie können einen benutzerdefinierten Avatar festlegen, indem Sie auf ein <a href="#avatars">Avatar Prefab</a> verweisen. Standardmäßig ist ein einfacher <code>DefaultAvatar</code> zugewiesen.</p></li><li><p><strong>Teleportation aktivieren</strong> Fügen Sie eine <code>TeleportTarget</code>-Komponente zu Objekthierarchien hinzu, auf die teleportiert werden kann. Um bestimmte Objekte auszuschließen, setzen Sie deren Layer auf <code>IgnoreRaycasting</code>.</p></li></ol><h3 id="multiplayer" tabindex="-1"><a class="header-anchor" href="#multiplayer"><span>Multiplayer</span></a></h3><ol><li><p><strong>Networking aktivieren</strong> Fügen Sie eine <code>SyncedRoom</code>-Komponente hinzu.</p></li><li><p><strong>Desktop Viewer Sync aktivieren</strong> Fügen Sie eine <code>SyncedCamera</code>-Komponente hinzu.</p></li><li><p><strong>Voice Chat aktivieren</strong> Fügen Sie eine <code>VoIP</code>-Komponente hinzu.</p></li></ol><div class="hint-container tip"><p class="hint-container-title">Szenenstruktur</p><p>Diese Komponenten können sich überall in Ihrer Hierarchie befinden. Sie können auch alle auf demselben GameObject liegen, was ein übliches Muster ist.</p></div><blockquote><p><strong><a href="https://castle.needle.tools/" target="_blank" rel="noopener noreferrer">Castle Builder</a></strong> verwendet alle oben genannten Funktionen für ein plattformübergreifendes Multiplayer-Sandbox-Erlebnis. – #madebyneedle 💚</p></blockquote><h3 id="spezielle-ar-komponenten" tabindex="-1"><a class="header-anchor" href="#spezielle-ar-komponenten"><span>Spezielle AR-Komponenten</span></a></h3><ol><li><strong>AR-Session-Root und -Skalierung definieren</strong> Fügen Sie Ihrem Root-Objekt eine <code>WebARSessionRoot</code>-Komponente hinzu. Bei AR-Erlebnissen möchten Sie die Szene oft so skalieren, dass sie in die reale Welt passt.</li><li>Definieren Sie die <strong>Benutzerskala</strong>, um den Benutzer beim Betreten von AR im Verhältnis zur Szene zu verkleinern (&lt; 1) oder zu vergrößern (&gt; 1).</li></ol><h3 id="steuerung-der-objektanzeige-f-r-xr" tabindex="-1"><a class="header-anchor" href="#steuerung-der-objektanzeige-f-r-xr"><span>Steuerung der Objektanzeige für XR</span></a></h3><ol><li><p><strong>Definieren Sie, ob ein Objekt im Browser, in AR, in VR, in der First Person oder in der Third Person sichtbar ist</strong> Fügen Sie dem Objekt, das Sie steuern möchten, eine <code>XR Flag</code>-Komponente hinzu.</p></li><li><p><strong>Ändern Sie die Optionen im Dropdown</strong> nach Bedarf. Gängige Anwendungsfälle sind</p><ul><li>Ausblenden von Böden beim Betreten von AR</li><li>Ausblenden von Avatar-Teilen in der First oder Third Person Ansicht. In der First-Person-Ansicht sollte eine Person zum Beispiel ihr eigenes Kopfmodell nicht sehen können.</li></ul></li></ol><h3 id="reisen-zwischen-vr-welten" tabindex="-1"><a class="header-anchor" href="#reisen-zwischen-vr-welten"><span>Reisen zwischen VR-Welten</span></a></h3><p>Needle Engine unterstützt den <a href="https://github.com/immersive-web/navigation" target="_blank" rel="noopener noreferrer"><code>sessiongranted</code></a>-Zustand. Dies ermöglicht Benutzern, nahtlos zwischen WebXR-Anwendungen zu wechseln, ohne eine immersive Sitzung zu verlassen – sie bleiben in VR oder AR.</p><p>Derzeit wird dies nur auf Oculus Quest 1, 2 und 3 im Oculus Browser unterstützt. Auf anderen Plattformen werden Benutzer aus ihrer aktuellen immersiven Sitzung geworfen und müssen auf der neuen Seite VR erneut betreten. Erfordert die Aktivierung eines Browser-Flags: <code>chrome://flags/#webxr-navigation-permission</code></p><ul><li><strong>Klicken Sie auf Objekte, um Links zu öffnen</strong> Fügen Sie die <code>OpenURL</code>-Komponente hinzu, die es sehr einfach macht, verbundene Welten zu erstellen.</li></ul><h2 id="scripting" tabindex="-1"><a class="header-anchor" href="#scripting"><span>Scripting</span></a></h2>',17)),n("p",null,[e[31]||(e[31]=i("Lesen Sie mehr über Scripting für XR in der ")),t(r,{to:"/lang/de/scripting.html#xr-event-methods"},{default:s(()=>e[30]||(e[30]=[i("XR-Scripting-Dokumentation")])),_:1})]),e[48]||(e[48]=l(`<h2 id="avatare" tabindex="-1"><a class="header-anchor" href="#avatare"><span>Avatare</span></a></h2><p>Auch wenn wir derzeit keine sofort einsatzbereite Integration externer Avatarsysteme anbieten, können Sie anwendungsspezifische Avatare oder benutzerdefinierte Systeme erstellen.</p><ul><li><strong>Einen benutzerdefinierten Avatar erstellen</strong><ul><li>Erstellen Sie ein leeres GameObject als Avatar-Wurzel</li><li>Fügen Sie ein Objekt mit dem Namen <code>Head</code> hinzu und fügen Sie eine <code>XRFlag</code> hinzu, die auf Third Person eingestellt ist</li><li>Fügen Sie Objekte mit den Namen <code>HandLeft</code> und <code>HandRight</code> hinzu</li><li>Fügen Sie Ihre Grafiken unterhalb dieser Objekte hinzu.</li></ul></li></ul><h3 id="experimentelle-avatar-komponenten" tabindex="-1"><a class="header-anchor" href="#experimentelle-avatar-komponenten"><span>Experimentelle Avatar-Komponenten</span></a></h3><p>Es gibt eine Reihe experimenteller Komponenten, um ausdrucksstärkere Avatare zu erstellen. Zu diesem Zeitpunkt empfehlen wir, sie zu duplizieren, um eigene Varianten zu erstellen, da sie später geändert oder entfernt werden könnten.</p><p><img src="https://user-images.githubusercontent.com/2693840/185243523-57c4b2a9-0ec7-4f88-b53b-585e879d504d.gif" alt="20220817-230858-87dG-Unity_PLjQ"><em>Beispiel Avatar Rig mit einfachem Halsmodell und Gliedmaßen-Constraints</em></p><ul><li><p><strong>Zufällige Spielerfarben</strong> Als Beispiel für die Avatar-Anpassung können Sie eine <code>PlayerColor</code>-Komponente zu Ihren Renderern hinzufügen. Diese zufällige Farbe wird zwischen den Spielern synchronisiert.</p></li><li><p><strong>Augenrotation</strong><code>AvatarEyeLook_Rotation</code> dreht GameObjects (Augen), um anderen Avataren und einem zufälligen Ziel zu folgen. Diese Komponente wird zwischen den Spielern synchronisiert.</p></li><li><p><strong>Augenblinzeln</strong><code>AvatarBlink_Simple</code> versteckt GameObjects (Augen) zufällig alle paar Sekunden und imitiert so ein Blinzeln.</p></li></ul><p><img src="https://user-images.githubusercontent.com/2693840/185233753-e6de49f0-31c3-4851-9919-551309303ebd.png" alt="image"><em>Beispiel Avatar Prefab Hierarchie</em></p><ul><li><p><strong>Offset Constraint</strong><code>OffsetConstraint</code> ermöglicht das Verschieben eines Objekts im Verhältnis zu einem anderen im Avatar-Raum. Dies ermöglicht es beispielsweise, dass ein Body dem Head folgt, aber die Rotation ausgerichtet bleibt. Es ermöglicht auch den Aufbau einfacher Halsmodelle.</p></li><li><p><strong>Limb Constraint</strong><code>BasicIKConstraint</code> ist ein sehr minimalistisches Constraint, das zwei Transforms und einen Hinweis benötigt. Dies ist nützlich, um einfache Arm- oder Beinketten zu konstruieren. Da die Rotation derzeit nicht richtig implementiert ist, müssen Arme und Beine möglicherweise rotationssymmetrisch sein, damit sie &quot;richtig aussehen&quot;. Es heißt aus gutem Grund &quot;Basic&quot;!</p></li></ul><h2 id="html-inhalts-overlays-in-ar" tabindex="-1"><a class="header-anchor" href="#html-inhalts-overlays-in-ar"><span>HTML-Inhalts-Overlays in AR</span></a></h2><p>Wenn Sie unterschiedliche HTML-Inhalte anzeigen möchten, je nachdem, ob der Client einen regulären Browser oder AR oder VR verwendet, können Sie einfach eine Reihe von HTML-Klassen verwenden. Dies wird über HTML-Elementklassen gesteuert. Um Inhalte beispielsweise auf dem Desktop und in AR erscheinen zu lassen, fügen Sie ein <code>&lt;div class=&quot;desktop ar&quot;&gt; ... &lt;/div&gt;</code> innerhalb des <code>&lt;needle-engine&gt;</code>-Tags hinzu:</p><div class="language-html" data-highlighter="shiki" data-ext="html" style="--shiki-light:#4c4f69;--shiki-dark:#c6d0f5;--shiki-light-bg:#eff1f5;--shiki-dark-bg:#303446;"><pre class="shiki shiki-themes catppuccin-latte catppuccin-frappe vp-code"><code><span class="line"><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">&lt;</span><span style="--shiki-light:#1E66F5;--shiki-dark:#8CAAEE;">needle-engine</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">    &lt;</span><span style="--shiki-light:#1E66F5;--shiki-dark:#8CAAEE;">div</span><span style="--shiki-light:#DF8E1D;--shiki-dark:#E5C890;"> class</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">=</span><span style="--shiki-light:#40A02B;--shiki-dark:#A6D189;">&quot;desktop ar&quot;</span><span style="--shiki-light:#DF8E1D;--shiki-dark:#E5C890;"> style</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">=</span><span style="--shiki-light:#40A02B;--shiki-dark:#A6D189;">&quot;</span><span style="--shiki-light:#4C4F69;--shiki-dark:#C6D0F5;">pointer-events:none;&quot;</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">        &lt;</span><span style="--shiki-light:#1E66F5;--shiki-dark:#8CAAEE;">div</span><span style="--shiki-light:#DF8E1D;--shiki-dark:#E5C890;"> class</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">=</span><span style="--shiki-light:#40A02B;--shiki-dark:#A6D189;">&quot;positioning-container&quot;</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">          &lt;</span><span style="--shiki-light:#1E66F5;--shiki-dark:#8CAAEE;">p</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">&gt;</span><span style="--shiki-light:#4C4F69;--shiki-dark:#C6D0F5;">Ihr Inhalt für AR und Desktop kommt hier rein</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">&lt;/</span><span style="--shiki-light:#1E66F5;--shiki-dark:#8CAAEE;">p</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">          &lt;</span><span style="--shiki-light:#1E66F5;--shiki-dark:#8CAAEE;">p</span><span style="--shiki-light:#DF8E1D;--shiki-dark:#E5C890;"> class</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">=</span><span style="--shiki-light:#40A02B;--shiki-dark:#A6D189;">&quot;only-in-ar&quot;</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">&gt;</span><span style="--shiki-light:#4C4F69;--shiki-dark:#C6D0F5;">Dies wird nur in AR sichtbar sein</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">&lt;/</span><span style="--shiki-light:#1E66F5;--shiki-dark:#8CAAEE;">p</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">        &lt;</span><span style="--shiki-light:#1E66F5;--shiki-dark:#8CAAEE;">div</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">    &lt;/</span><span style="--shiki-light:#1E66F5;--shiki-dark:#8CAAEE;">div</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">&gt;</span></span>
<span class="line"><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">&lt;/</span><span style="--shiki-light:#1E66F5;--shiki-dark:#8CAAEE;">needle-engine</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">&gt;</span></span></code></pre></div><p>Inhalts-Overlays werden mithilfe der optionalen <code>dom-overlay</code>-Funktion implementiert, die normalerweise auf bildschirmbasierten AR-Geräten (Telefone, Tablets) unterstützt wird.</p><p>Verwenden Sie die Klasse <code>.ar-session-active</code>, um spezifische Inhalte während der AR-Sitzung ein-/auszublenden. Die Pseudoklasse <a href="https://www.w3.org/TR/webxr-dom-overlays-1/#css-pseudo-class" target="_blank" rel="noopener noreferrer"><code>:xr-overlay</code></a> sollte derzeit nicht verwendet werden, da ihre Verwendung den WebXR Viewer von Mozilla beschädigt.</p><div class="language-css" data-highlighter="shiki" data-ext="css" style="--shiki-light:#4c4f69;--shiki-dark:#c6d0f5;--shiki-light-bg:#eff1f5;--shiki-dark-bg:#303446;"><pre class="shiki shiki-themes catppuccin-latte catppuccin-frappe vp-code"><code><span class="line"><span style="--shiki-light:#7C7F93;--shiki-dark:#949CBB;">.</span><span style="--shiki-light:#DF8E1D;--shiki-dark:#E5C890;">only-in-ar</span><span style="--shiki-light:#7C7F93;--shiki-dark:#949CBB;"> {</span></span>
<span class="line"><span style="--shiki-light:#1E66F5;--shiki-dark:#8CAAEE;">  display</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">:</span><span style="--shiki-light:#4C4F69;--shiki-dark:#C6D0F5;"> none</span><span style="--shiki-light:#7C7F93;--shiki-dark:#949CBB;">;</span></span>
<span class="line"><span style="--shiki-light:#7C7F93;--shiki-dark:#949CBB;">}</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#7C7F93;--shiki-dark:#949CBB;">.</span><span style="--shiki-light:#DF8E1D;--shiki-dark:#E5C890;">ar-session-active</span><span style="--shiki-light:#7C7F93;--shiki-dark:#949CBB;"> .</span><span style="--shiki-light:#DF8E1D;--shiki-dark:#E5C890;">only-in-ar</span><span style="--shiki-light:#7C7F93;--shiki-dark:#949CBB;"> {</span></span>
<span class="line"><span style="--shiki-light:#1E66F5;--shiki-dark:#8CAAEE;">  display</span><span style="--shiki-light:#179299;--shiki-dark:#81C8BE;">:</span><span style="--shiki-light:#4C4F69;--shiki-dark:#C6D0F5;">initial</span><span style="--shiki-light:#7C7F93;--shiki-dark:#949CBB;">;</span></span>
<span class="line"><span style="--shiki-light:#7C7F93;--shiki-dark:#949CBB;">}</span></span></code></pre></div><p>Es ist erwähnenswert, dass das Overlay-Element <a href="https://www.w3.org/TR/webxr-dom-overlays-1/#ua-style-sheet-defaults" target="_blank" rel="noopener noreferrer">während der XR-Sitzung immer im Vollbildmodus angezeigt wird</a>, unabhängig von angewendeten Stildefinitionen. Wenn Sie Elemente anders ausrichten möchten, sollten Sie einen Container <em>innerhalb</em> des Elements mit der Klasse <code>class=&quot;ar&quot;</code> erstellen.</p>`,16)),t(a,{src:"https://engine.needle.tools/samples-uploads/ar-overlay/"}),e[49]||(e[49]=n("h2",{id:"augmented-reality-und-webxr-auf-ios",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#augmented-reality-und-webxr-auf-ios"},[n("span",null,"Augmented Reality und WebXR auf iOS")])],-1)),e[50]||(e[50]=n("p",null,"Augmented Reality-Erlebnisse auf iOS sind etwas eingeschränkt, da Apple WebXR derzeit auf iOS-Geräten nicht unterstützt.",-1)),n("p",null,[e[34]||(e[34]=i("Needle Engine's ")),t(r,{to:"/lang/de/everywhere-actions.html"},{default:s(()=>e[32]||(e[32]=[i("Everywhere Actions")])),_:1}),e[35]||(e[35]=i(" wurden entwickelt, um diese Lücke zu schließen und automatische interaktive Funktionen auf iOS-Geräten für Szenen zu ermöglichen, die aus spezifischen Komponenten bestehen. Sie unterstützen eine Teilmenge der Funktionalität, die in WebXR verfügbar ist, zum Beispiel räumliches Audio, Bild-Tracking, Animationen und mehr. Weitere Informationen finden Sie in ")),t(r,{to:"/lang/de/everywhere-actions.html"},{default:s(()=>e[33]||(e[33]=[i("der Dokumentation")])),_:1}),e[36]||(e[36]=i("."))]),e[51]||(e[51]=n("div",{class:"hint-container tip"},[n("p",{class:"hint-container-title"},"Begrenzte Unterstützung für benutzerdefinierten Code in QuickLook"),n("p",null,"Apple hat starke Einschränkungen hinsichtlich der Art von Inhalten festgelegt, die in QuickLook verwendet werden können. Daher können benutzerdefinierte Skriptkomponenten nicht automatisch für die Verwendung in AR auf iOS konvertiert werden. Sie können mithilfe unserer Everywhere Actions API Unterstützung für einige Arten von benutzerdefiniertem Code hinzufügen.")],-1)),e[52]||(e[52]=n("h3",{id:"musikinstrument-webxr-und-quicklook-unterst-tzung",tabindex:"-1"},[n("a",{class:"header-anchor",href:"#musikinstrument-webxr-und-quicklook-unterst-tzung"},[n("span",null,"Musikinstrument – WebXR- und QuickLook-Unterstützung")])],-1)),e[53]||(e[53]=n("p",null,"Hier ist ein Beispiel für ein Musikinstrument, das Everywhere Actions verwendet und daher in Browsern und in AR auf iOS-Geräten funktioniert. Es verwendet räumliches Audio, Animation und Tap-Interaktionen.",-1)),t(a,{src:"https://engine.needle.tools/samples-uploads/musical-instrument"}),e[54]||(e[54]=l('<h3 id="everywhere-actions-und-andere-optionen-f-r-ios-ar" tabindex="-1"><a class="header-anchor" href="#everywhere-actions-und-andere-optionen-f-r-ios-ar"><span>Everywhere Actions und andere Optionen für iOS AR</span></a></h3><p>Es gibt auch andere Optionen, um iOS-Benutzer zu noch leistungsfähigeren interaktiven AR-Erlebnissen zu führen:</p><ol start="3"><li><strong>On-the-fly-Export von Inhalten als USDZ-Dateien.</strong> Diese Dateien können auf iOS-Geräten in AR angezeigt werden. Beim Export aus Szenen mit Everywhere Actions ist die Interaktivität dieselbe, mehr als ausreichend für Produktkonfiguratoren, narrative Erlebnisse und Ähnliches. Ein Beispiel ist <a href="https://castle.needle.tools" target="_blank" rel="noopener noreferrer">Castle Builder</a>, wo Kreationen (nicht die Live-Sitzung) in AR betrachtet werden können.</li></ol><blockquote><p><strong><a href="https://accurate-tree-observation.glitch.me/" target="_blank" rel="noopener noreferrer">Encryption in Space</a></strong> verwendet diesen Ansatz. Spieler können kollaborativ Text in die Szene auf ihren Bildschirmen platzieren und dann die Ergebnisse in AR auf iOS ansehen. Auf Android können sie auch direkt in WebXR interagieren. – #madewithneedle von Katja Rempel 💚</p></blockquote><ol><li><p><strong>Führen von Benutzern zu WebXR-kompatiblen Browsern auf iOS.</strong> Je nach Zielgruppe können Sie Benutzer auf iOS beispielsweise zum <a href="https://apps.apple.com/de/app/webxr-viewer/id1295998056" target="_blank" rel="noopener noreferrer">WebXR Viewer</a> von Mozilla führen, um AR auf iOS zu erleben.</p></li><li><p><strong>Verwendung des Kamerazugriffs und benutzerdefinierter Algorithmen auf iOS-Geräten.</strong> Man kann den Zugriff auf das Kamerabild anfordern und benutzerdefinierte Algorithmen ausführen, um die Geräteposition zu bestimmen. Obwohl wir derzeit keine integrierten Komponenten dafür bereitstellen, finden Sie hier einige Verweise auf Bibliotheken und Frameworks, die wir in Zukunft ausprobieren möchten:</p><ul><li><a href="https://github.com/AR-js-org/AR.js" target="_blank" rel="noopener noreferrer">AR.js</a> (Open Source) <ul><li><a href="https://github.com/FireDragonGameStudio/NeedleAndARjs" target="_blank" rel="noopener noreferrer">Experimentelle AR.js-Integration</a> von FireDragonGameStudio</li></ul></li><li><a href="https://github.com/hiukim/mind-ar-js" target="_blank" rel="noopener noreferrer">Mind AR</a> (Open Source)</li><li><a href="https://www.8thwall.com/" target="_blank" rel="noopener noreferrer">8th Wall</a> (kommerziell)</li></ul></li></ol><h2 id="bild-tracking" tabindex="-1"><a class="header-anchor" href="#bild-tracking"><span>Bild-Tracking</span></a></h2><p>Needle Engine unterstützt <strong>WebXR Bild-Tracking</strong> (<a href="https://engine.needle.tools/samples/image-tracking?utm_source=docs&amp;utm_content=xr" target="_blank" rel="noopener noreferrer">Live-Demo</a>) auf Android und <strong>QuickLook Bild-Tracking</strong> auf iOS.</p>',7)),n("p",null,[e[38]||(e[38]=i("Zusätzliche Dokumentation finden Sie im Abschnitt ")),t(r,{to:"/lang/de/everywhere-actions.html#image-tracking"},{default:s(()=>e[37]||(e[37]=[i("Everywhere Actions")])),_:1}),e[39]||(e[39]=i("."))]),e[55]||(e[55]=l('<div class="hint-container warning"><p class="hint-container-title">WebXR Bild-Tracking befindet sich noch in einer &quot;Draft&quot;-Phase und ist nicht allgemein verfügbar</p><p>Bislang konnten sich die Browser-Anbieter noch nicht auf die endgültige Image Tracking API für WebXR einigen. Solange die Spezifikation in der &quot;Draft&quot;-Phase ist (<a href="https://github.com/immersive-web/marker-tracking/blob/main/explainer.md" target="_blank" rel="noopener noreferrer">Marker Tracking Explainer</a>), müssen Sie und die Benutzer Ihrer App die folgenden Schritte ausführen, um WebXR ImageTracking auf Android-Geräten zu aktivieren:</p><ol><li>Besuchen Sie <code>chrome://flags</code> in Ihrem Android Chrome-Browser</li><li>Suchen und aktivieren Sie die Option <code>WebXR Incubations</code></li></ol></div><p>Ohne diese Spezifikation kann man immer noch den Zugriff auf das Kamerabild anfordern und benutzerdefinierte Algorithmen ausführen, um die Geräteposition zu bestimmen. Der Nachteil ist, dass Benutzer zusätzliche Berechtigungen wie Kamerazugriff akzeptieren müssen und das Tracking nicht so genau sein wird wie mit den nativen Fähigkeiten des Geräts.</p><p>Hier sind einige Bibliotheken, um Bild-Tracking basierend auf Kamerazugriff und lokalen Computer-Vision-Algorithmen hinzuzufügen:</p><ul><li><a href="https://github.com/FireDragonGameStudio/NeedleAndARjs" target="_blank" rel="noopener noreferrer">Experimentelle AR.js-Integration mit Needle Engine</a> von FireDragonGameStudio</li><li><a href="https://github.com/AR-js-org/AR.js" target="_blank" rel="noopener noreferrer">AR.js</a> (Open Source)</li><li><a href="https://github.com/hiukim/mind-ar-js" target="_blank" rel="noopener noreferrer">Mind AR</a> (Open Source)</li></ul><h2 id="referenzen" tabindex="-1"><a class="header-anchor" href="#referenzen"><span>Referenzen</span></a></h2><p><a href="https://www.w3.org/TR/webxr/" target="_blank" rel="noopener noreferrer">WebXR Device API</a><a href="https://caniuse.com/webxr" target="_blank" rel="noopener noreferrer">caniuse: WebXR</a><a href="https://developer.apple.com/augmented-reality/quick-look/" target="_blank" rel="noopener noreferrer">Apples vorläufige USD-Verhaltensweisen</a> Seite automatisch mit KI übersetzt</p>',6))])}const b=d(p,[["render",k]]),c=JSON.parse('{"path":"/lang/de/xr.html","title":"VR & AR (WebXR)","lang":"de-DE","frontmatter":{"title":"VR & AR (WebXR)","head":[["meta",{"name":"og:image","content":"https://engine.needle.tools/docs/.preview/vr & ar_de.png"}],["meta",{"name":"og:description","content":"---\\nNeedle Engine unterstützt die vollständige WebXR-Spezifikation, einschließlich AR und VR. WebXR ist ein offizieller Webstandard, der immersive Erlebnisse ins Web bringt, mit allen Vorteilen des Webs: keine Installation, kein App Store, keine SDKs erforderlich.\\nAlle Geräte mit einem Browser können mit Needle erstellte Apps ausführen. Wenn der Browser WebXR unterstützt, funktionieren Ihre Apps automatisch auch in XR, indem sie unsere integrierten Komponenten verwenden. Dazu gehören Desktop-Browser, mobile Browser, viele Browser auf AR/VR-Headsets, aber auch andere aufkommende Technologien wie Looking Glass-Displays, Smart Glasses und mehr.\\n:::tip App-freie iOS AR-Unterstützung über USDZ/QuickLook\\nWährend iOS-Geräte noch keine offizielle WebXR-Unterstützung bieten, unterstützt Needle die Erstellung von AR-Erlebnissen auf iOS mithilfe von Everywhere Actions. Weitere Details finden Sie im iOS-Abschnitt. Sie können reichhaltige, interaktive Erlebnisse erstellen, die nahtlos in AR auf iOS-Geräten funktionieren, selbst mit den Einschränkungen, die Apple festgelegt hat.\\nWenn Sie den AR-Modus auf iOS aufrufen, konvertiert Needle Ihre Szene automatisch in eine USDZ-Datei, die dann in AR mithilfe von Apples QuickLook angezeigt wird. Objekte, Materialien, Audio, Animationen und Everywhere Actions bleiben erhalten.\\n:::\\nDie folgende Tabelle listet einige der Geräte auf, die wir erfolgreich mit Needle Engine getestet haben.\\nWenn ein neues Gerät auf den Markt kommt, das WebXR unterstützt, funktioniert es ohne weiteres mit Ihren Apps. Dies ist einer der großen Vorteile der Entwicklung mit dem Browser als Plattform – die Kompatibilität ist nicht auf eine bestimmte Gruppe von Geräten oder SDKs beschränkt."}]],"description":"---\\nNeedle Engine unterstützt die vollständige WebXR-Spezifikation, einschließlich AR und VR. WebXR ist ein offizieller Webstandard, der immersive Erlebnisse ins Web bringt, mit allen Vorteilen des Webs: keine Installation, kein App Store, keine SDKs erforderlich.\\nAlle Geräte mit einem Browser können mit Needle erstellte Apps ausführen. Wenn der Browser WebXR unterstützt, funktionieren Ihre Apps automatisch auch in XR, indem sie unsere integrierten Komponenten verwenden. Dazu gehören Desktop-Browser, mobile Browser, viele Browser auf AR/VR-Headsets, aber auch andere aufkommende Technologien wie Looking Glass-Displays, Smart Glasses und mehr.\\n:::tip App-freie iOS AR-Unterstützung über USDZ/QuickLook\\nWährend iOS-Geräte noch keine offizielle WebXR-Unterstützung bieten, unterstützt Needle die Erstellung von AR-Erlebnissen auf iOS mithilfe von Everywhere Actions. Weitere Details finden Sie im iOS-Abschnitt. Sie können reichhaltige, interaktive Erlebnisse erstellen, die nahtlos in AR auf iOS-Geräten funktionieren, selbst mit den Einschränkungen, die Apple festgelegt hat.\\nWenn Sie den AR-Modus auf iOS aufrufen, konvertiert Needle Ihre Szene automatisch in eine USDZ-Datei, die dann in AR mithilfe von Apples QuickLook angezeigt wird. Objekte, Materialien, Audio, Animationen und Everywhere Actions bleiben erhalten.\\n:::\\nDie folgende Tabelle listet einige der Geräte auf, die wir erfolgreich mit Needle Engine getestet haben.\\nWenn ein neues Gerät auf den Markt kommt, das WebXR unterstützt, funktioniert es ohne weiteres mit Ihren Apps. Dies ist einer der großen Vorteile der Entwicklung mit dem Browser als Plattform – die Kompatibilität ist nicht auf eine bestimmte Gruppe von Geräten oder SDKs beschränkt."},"headers":[{"level":2,"title":"Unterstützte Geräte","slug":"unterst-tzte-ger-te","link":"#unterst-tzte-ger-te","children":[]},{"level":2,"title":"VR-, AR- und QuickLook-Beispiele","slug":"vr-ar-und-quicklook-beispiele","link":"#vr-ar-und-quicklook-beispiele","children":[]},{"level":2,"title":"Hinzufügen von VR- und AR-Funktionen zu einer Szene","slug":"hinzuf-gen-von-vr-und-ar-funktionen-zu-einer-szene","link":"#hinzuf-gen-von-vr-und-ar-funktionen-zu-einer-szene","children":[{"level":3,"title":"Grundfunktionen","slug":"grundfunktionen","link":"#grundfunktionen","children":[]},{"level":3,"title":"Multiplayer","slug":"multiplayer","link":"#multiplayer","children":[]},{"level":3,"title":"Spezielle AR-Komponenten","slug":"spezielle-ar-komponenten","link":"#spezielle-ar-komponenten","children":[]},{"level":3,"title":"Steuerung der Objektanzeige für XR","slug":"steuerung-der-objektanzeige-f-r-xr","link":"#steuerung-der-objektanzeige-f-r-xr","children":[]},{"level":3,"title":"Reisen zwischen VR-Welten","slug":"reisen-zwischen-vr-welten","link":"#reisen-zwischen-vr-welten","children":[]}]},{"level":2,"title":"Scripting","slug":"scripting","link":"#scripting","children":[]},{"level":2,"title":"Avatare","slug":"avatare","link":"#avatare","children":[{"level":3,"title":"Experimentelle Avatar-Komponenten","slug":"experimentelle-avatar-komponenten","link":"#experimentelle-avatar-komponenten","children":[]}]},{"level":2,"title":"HTML-Inhalts-Overlays in AR","slug":"html-inhalts-overlays-in-ar","link":"#html-inhalts-overlays-in-ar","children":[]},{"level":2,"title":"Augmented Reality und WebXR auf iOS","slug":"augmented-reality-und-webxr-auf-ios","link":"#augmented-reality-und-webxr-auf-ios","children":[{"level":3,"title":"Musikinstrument – WebXR- und QuickLook-Unterstützung","slug":"musikinstrument-webxr-und-quicklook-unterst-tzung","link":"#musikinstrument-webxr-und-quicklook-unterst-tzung","children":[]},{"level":3,"title":"Everywhere Actions und andere Optionen für iOS AR","slug":"everywhere-actions-und-andere-optionen-f-r-ios-ar","link":"#everywhere-actions-und-andere-optionen-f-r-ios-ar","children":[]}]},{"level":2,"title":"Bild-Tracking","slug":"bild-tracking","link":"#bild-tracking","children":[]},{"level":2,"title":"Referenzen","slug":"referenzen","link":"#referenzen","children":[]}],"git":{"updatedTime":1745311490000,"contributors":[{"name":"Marcel Wiessler","username":"","email":"marcel@gaisterhand.de","commits":1}],"changelog":[{"hash":"25e22e2b0b9e4fc1e515be2b189c24864e21ac9f","time":1745311490000,"email":"marcel@gaisterhand.de","author":"Marcel Wiessler","message":"add multilanguage support"}]},"filePathRelative":"lang/de/xr.md"}');export{b as comp,c as data};
